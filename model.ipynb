{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1jr1UlZM63pg6NBauHzo8gpU6LF1HQNFc",
      "authorship_tag": "ABX9TyMSVW/XbOdFKoqXDbjjkP0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharon-kathambi/data-segmentation-with-unet/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r_Ebvvbwpm1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbecade-1069-4626-d999-814a3e711c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import tensorflow as tf\n",
        "\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "EbfZZGbICHau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Dataset into Training and Test"
      ],
      "metadata": {
        "id": "w_NHE4o1WuV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "source_folder = \"/content/drive/MyDrive/Dataset_BUSI_with_GT\"\n",
        "train_folder = \"data/traindataset\"\n",
        "test_folder = \"data/testdataset\"\n",
        "\n",
        "# Define categories\n",
        "categories = [\"benign\", \"malignant\", \"normal\"]\n",
        "\n",
        "# Create train and test directories with category subfolders\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(train_folder, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_folder, category), exist_ok=True)\n",
        "\n",
        "# Function to move images and masks\n",
        "def move_image_and_mask(image_list, src_category_path, dest_category_path):\n",
        "    for img in image_list:\n",
        "        img_path = os.path.join(src_category_path, img)\n",
        "        mask_path = os.path.join(src_category_path, img.replace('.png', '_mask.png'))\n",
        "\n",
        "        # Copy image\n",
        "        shutil.copy2(img_path, os.path.join(dest_category_path, img))\n",
        "\n",
        "        # Copy mask if it exists\n",
        "        if os.path.exists(mask_path):\n",
        "            shutil.copy2(mask_path, os.path.join(dest_category_path, os.path.basename(mask_path)))\n",
        "\n",
        "# Process each category\n",
        "for category in categories:\n",
        "    category_path = os.path.join(source_folder, category)\n",
        "    train_category_path = os.path.join(train_folder, category)\n",
        "    test_category_path = os.path.join(test_folder, category)\n",
        "\n",
        "    # Get all images (excluding masks)\n",
        "    all_images = [f for f in os.listdir(category_path) if f.endswith(('.png')) and not f.endswith('_mask.png')]\n",
        "\n",
        "    # Shuffle images randomly\n",
        "    random.shuffle(all_images)\n",
        "\n",
        "    # Split 80% for training and 20% for testing\n",
        "    split_index = int(0.85 * len(all_images))\n",
        "    train_images = all_images[:split_index]\n",
        "    test_images = all_images[split_index:]\n",
        "\n",
        "    # Move images and masks\n",
        "    move_image_and_mask(train_images, category_path, train_category_path)\n",
        "    move_image_and_mask(test_images, category_path, test_category_path)\n",
        "\n",
        "    print(f\"{category}: Training images = {len(train_images)}, Testing images = {len(test_images)}\")\n",
        "\n",
        "print(\"Dataset split completed successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sP5_BifW0h3",
        "outputId": "be1ade8a-27da-477c-e96b-5d91fb2cc2e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benign: Training images = 385, Testing images = 69\n",
            "malignant: Training images = 179, Testing images = 32\n",
            "normal: Training images = 113, Testing images = 20\n",
            "Dataset split completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "13qPuo4lVvqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "2tQQGoXQkH0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Image parameters\n",
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "IMG_CHANNELS = 3  # Color images (RGB)\n",
        "\n",
        "def load_dataset(root_dir):\n",
        "    categories = [\"benign\", \"malignant\", \"normal\"]\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for category in categories:\n",
        "        folder_path = os.path.join(root_dir, category)\n",
        "\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".png\") and \"_mask\" not in filename:\n",
        "                # Load the color image (RGB)\n",
        "                img_path = os.path.join(folder_path, filename)\n",
        "                img = load_img(img_path, color_mode=\"rgb\", target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "                img = img_to_array(img) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "                # Load the corresponding mask (grayscale)\n",
        "                mask_filename = filename.replace(\".png\", \"_mask.png\")\n",
        "                mask_path = os.path.join(folder_path, mask_filename)\n",
        "\n",
        "                if os.path.exists(mask_path):\n",
        "                    mask = load_img(mask_path, color_mode=\"grayscale\", target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "                    mask = img_to_array(mask) / 255.0\n",
        "                    mask = (mask > 0.5).astype(np.float32)  # Binary mask\n",
        "\n",
        "                    images.append(img)\n",
        "                    masks.append(mask)\n",
        "                else:\n",
        "                    print(f\"Warning: No mask found for {filename}\")\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "dataset_path = \"/content/data/traindataset\"\n",
        "X, Y = load_dataset(dataset_path)\n",
        "\n",
        "# Split into training (85%) and validation (15%)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "\n",
        "# Normalize images\n",
        "#X_train = X_train.astype('float32') / 255.0\n",
        "#X_val = X_val.astype('float32') / 255.0\n",
        "\n",
        "# Normalize and reshape masks\n",
        "#Y_train = (Y_train.astype('float32') / 255.0).squeeze()\n",
        "#Y_val = (Y_val.astype('float32') / 255.0).squeeze()\n",
        "\n",
        "#Y_train = np.expand_dims(Y_train, axis=-1)\n",
        "#Y_val = np.expand_dims(Y_val, axis=-1)\n",
        "\n",
        "# Print shapes for verification\n",
        "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, Y_val shape: {Y_val.shape}\")\n",
        "\n",
        "\n",
        "print(f\"Training: {len(X_train)} images, Validation: {len(X_val)} images\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(\"Y_val shape:\", Y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJEv6ezcdGVx",
        "outputId": "98ad7772-51d9-4ad9-9246-b6faad22a28b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (563, 512, 512, 3), Y_train shape: (563, 512, 512, 1)\n",
            "X_val shape: (100, 512, 512, 3), Y_val shape: (100, 512, 512, 1)\n",
            "Training: 563 images, Validation: 100 images\n",
            "X_train shape: (563, 512, 512, 3)\n",
            "Y_train shape: (563, 512, 512, 1)\n",
            "Y_val shape: (100, 512, 512, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-unet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GjXElCwk-jG",
        "outputId": "726a2cb8-8eb4-4b43-acdb-544f69645ba0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-unet in /usr/local/lib/python3.11/dist-packages (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJpTcjK7B7fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "3zabfV3ej_W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_unet.models import custom_unet\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Set parameters\n",
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "IMG_CHANNELS = 3  # RGB images\n",
        "BATCH_SIZE = 8\n",
        "INITIAL_LR = 0.0001\n",
        "EPOCHS = 50\n",
        "\n",
        "# Learning rate scheduler (alternative to StepLR)\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=INITIAL_LR,\n",
        "    decay_steps=0.5 * (len(X_train) // BATCH_SIZE),\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "# Define Dice Coefficient & Loss\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "# Build U-Net Model\n",
        "model = custom_unet(input_shape=(512, 512, 3),\n",
        "                    filters=32, use_batch_norm=True,\n",
        "                    num_classes=1, activation=\"sigmoid\")\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
        "              loss=dice_loss,\n",
        "              metrics=[dice_coefficient])\n",
        "\n",
        "# Data Augmentation\n",
        "data_gen_args = dict(rotation_range=15,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     horizontal_flip=True,\n",
        "                     fill_mode=\"nearest\")\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "image_datagen.fit(X_train, augment=True)\n",
        "mask_datagen.fit(Y_train, augment=True)\n",
        "\n",
        "image_generator = image_datagen.flow(X_train, batch_size=BATCH_SIZE, seed=42)\n",
        "mask_generator = mask_datagen.flow(Y_train, batch_size=BATCH_SIZE, seed=42)\n",
        "\n",
        "def data_generator(image_gen, mask_gen):\n",
        "    while True:\n",
        "        img_batch = next(image_gen)[0]\n",
        "        mask_batch = next(mask_gen)[0]\n",
        "\n",
        "        # Ensure masks have the correct shape (BATCH_SIZE, 512, 512, 1)\n",
        "        if len(mask_batch.shape) == 3:\n",
        "            mask_batch = np.expand_dims(mask_batch, axis=-1)\n",
        "\n",
        "        yield img_batch, mask_batch\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(image_generator, mask_generator),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 1), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=100).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Custom Callback to Track Metrics\n",
        "class MetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.dice_coeffs = []\n",
        "        self.precisions = []\n",
        "        self.recalls = []\n",
        "        self.f1_scores = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        Y_pred = (self.model.predict(X_val) > 0.5).astype(np.uint8)\n",
        "\n",
        "        y_true_flat = Y_val.flatten()\n",
        "        y_pred_flat = Y_pred.flatten()\n",
        "\n",
        "        dice = dice_coefficient(Y_val, Y_pred).numpy()\n",
        "        precision = precision_score(y_true_flat, y_pred_flat, zero_division=1)\n",
        "        recall = recall_score(y_true_flat, y_pred_flat, zero_division=1)\n",
        "        f1 = f1_score(y_true_flat, y_pred_flat, zero_division=1)\n",
        "\n",
        "        self.dice_coeffs.append(dice)\n",
        "        self.precisions.append(precision)\n",
        "        self.recalls.append(recall)\n",
        "        self.f1_scores.append(f1)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} - Dice: {dice:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "# Train Model with Metrics Logging\n",
        "metrics_callback = MetricsCallback()\n",
        "history = model.fit(X_train,           # Training images\n",
        "                    Y_train,\n",
        "                    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(X_val, Y_val),\n",
        "                    callbacks=[metrics_callback])\n",
        "\n",
        "# üìä Plot Metrics Over Epochs\n",
        "epochs_range = range(1, EPOCHS + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, metrics_callback.dice_coeffs, 'b', label=\"Dice Coefficient\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Dice Coefficient\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, metrics_callback.precisions, 'g', label=\"Precision\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs_range, metrics_callback.recalls, 'r', label=\"Recall\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs_range, metrics_callback.f1_scores, 'm', label=\"F1 Score\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle(\"Training Metrics Over Epochs\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vcH56g_3kC9B",
        "outputId": "1c861117-6a4e-45a7-a4de-1463d4b82437"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor']\n",
            "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/70\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m10s\u001b[0m 1s/step - dice_coefficient: 0.1582 - loss: 0.8418  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-4-d49364dab1a8>\", line 114, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 395, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 484, in evaluate\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.36 = (f32[32,32,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,512,512]{3,2,1,0} %concatenate.7, f32[32,64,3,3]{3,2,1,0} %bitcast.1783), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_16_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1090519040 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_15724]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d49364dab1a8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# Train Model with Metrics Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mmetrics_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetricsCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m history = model.fit(X_train,           # Training images\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-4-d49364dab1a8>\", line 114, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 395, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 484, in evaluate\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv.36 = (f32[32,32,512,512]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,512,512]{3,2,1,0} %concatenate.7, f32[32,64,3,3]{3,2,1,0} %bitcast.1783), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_16_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1196}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1090519040 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_15724]"
          ]
        }
      ]
    }
  ]
}